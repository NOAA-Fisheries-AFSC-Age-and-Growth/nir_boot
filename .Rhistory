dev.new(width=12, height=12, unit="in",noRStudioGD = TRUE)
par(mar = c(5, 5, 2, 2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(df$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5)
text(205,175,label=paste("n = 573"),cex=1.5, pos=4)
text(205,190,label=paste("A"),cex=1.5, pos=4)
hist(seGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5)
text(205,175,label=paste("n = 108"),cex=2, pos=4)
text(205,190,label=paste("B"),cex=2, pos=4)
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5)
text(205,175,label=paste("n = 465"),cex=2, pos=4)
text(205,190,label=paste("C"),cex=2, pos=4)
}
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
{
dev.new(width=12, height=12, unit="in",noRStudioGD = TRUE)
par(mar = c(5, 5, 2, 2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(df$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 573"),cex=1.5, pos=4)
text(205,190,label=paste("A"),cex=1.5, pos=4)
hist(seGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 108"),cex=1.5, pos=4)
text(205,190,label=paste("B"),cex=1.5, pos=4)
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 465"),cex=1.5, pos=4)
text(205,190,label=paste("C"),cex=1.5, pos=4)
}
{
dev.new(width=12, height=12, unit="in",noRStudioGD = TRUE)
par(mar = c(6, 5, 2, 2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(df$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 573"),cex=1.5, pos=4)
text(205,190,label=paste("A"),cex=1.5, pos=4)
hist(seGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 108"),cex=1.5, pos=4)
text(205,190,label=paste("B"),cex=1.5, pos=4)
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 465"),cex=1.5, pos=4)
text(205,190,label=paste("C"),cex=1.5, pos=4)
}
{
dev.new(width=12, height=12, unit="in",noRStudioGD = TRUE)
par(mar = c(1, 5, 2, 2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(df$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 573"),cex=1.5, pos=4)
text(205,190,label=paste("A"),cex=1.5, pos=4)
hist(seGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 108"),cex=1.5, pos=4)
text(205,190,label=paste("B"),cex=1.5, pos=4)
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 465"),cex=1.5, pos=4)
text(205,190,label=paste("C"),cex=1.5, pos=4)
}
{
dev.new(width=12, height=12, unit="in",noRStudioGD = TRUE)
par(mar = c(5, 6, 2, 2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(df$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 573"),cex=1.5, pos=4)
text(205,190,label=paste("A"),cex=1.5, pos=4)
hist(seGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 108"),cex=1.5, pos=4)
text(205,190,label=paste("B"),cex=1.5, pos=4)
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 465"),cex=1.5, pos=4)
text(205,190,label=paste("C"),cex=1.5, pos=4)
}
{
dev.new(width=12, height=12, unit="in",noRStudioGD = TRUE)
par(mar = c(5, 5, 2, 2))
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(df$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 573"),cex=1.5, pos=4)
text(205,190,label=paste("A"),cex=1.5, pos=4)
hist(seGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 108"),cex=1.5, pos=4)
text(205,190,label=paste("B"),cex=1.5, pos=4)
hist(nGOM$Whole_FL_Converted, breaks = seq(0,600,50), xaxs = "i", yaxs = "i",
xlim=c(200,600),ylim=c(0,200), xlab = "Fork Length mm", main = NA,
cex.lab=1.5, cex.axis=1.5, las = 1)
text(205,175,label=paste("n = 465"),cex=1.5, pos=4)
text(205,190,label=paste("C"),cex=1.5, pos=4)
}
library(readxl)
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
View(df)
df[-1:-5,]
summary(lm(Aged~Leave, df))
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
df <- df[-1:-5,]
summary(lm(Aged~Leave, df))
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Aged~Leave, df)) #p-value 0.24
summary(lm(Total~Leave, df)) #p-value 0.24
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Aged~Leave, df)) #p-value 0.58
View(df)
summary(lm(Total~Leave, df)) #p-value 0.07
df <- df[-1:-5,]
summary(lm(Aged~Leave, df)) #p-value 0.24
View(df)
df <- df[-6,]
summary(lm(Aged~Leave, df)) #p-value 0.17
summary(lm(Aged~Scan, df)) #p-value 0.63
summary(lm(Aged~Scan, df)) #p-value 0.29
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Aged~Leave, df)) #p-value 0.58
summary(lm(Total~Leave, df)) #p-value 0.09
summary(lm(Aged~Scan, df)) #p-value 0.29
summary(lm(Total~Scan, df)) #p-value 0.29
df <- df[-1:-5,]#remove training weeks
summary(lm(Aged~Leave, df)) #p-value 0.17
summary(lm(Total~Leave, df)) #p-value 0.13
summary(lm(Aged~Scan, df)) #p-value 0.87
summary(lm(Total~Scan, df)) #p-value 0.54
df <- df[-6,]#remove week out on leave entire week
df <- df[-6,]#remove week out on leave entire week
summary(lm(Aged~Leave, df)) #p-value 0.17
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Aged~Leave, df)) #p-value 0.58
summary(lm(Total~Leave, df)) #p-value 0.13
summary(lm(Aged~Scan, df)) #p-value 0.87
summary(lm(Total~Scan, df)) #p-value 0.54
df <- df[-1:-5,]#remove training weeks
summary(lm(Aged~Leave, df)) #p-value 0.17
summary(lm(Total~Leave, df)) #p-value 0.16
summary(lm(Aged~Scan, df)) #p-value 0.22
summary(lm(Total~Scan, df)) #p-value 0.63
df <- df[-6,]#remove week out on leave entire week
summary(lm(Aged~Leave, df)) #p-value 0.
summary(lm(Aged~Leave, df)) #p-value 0.63
summary(lm(Total~Leave, df)) #p-value 0.16
summary(lm(Aged~Scan, df)) #p-value 0.22
summary(lm(Total~Scan, df)) #p-value 0.63
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Aged~Week, df)) #p-value 0.58
summary(lm(Total~Week, df)) #p-value 0.58
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Total~Week, df)) #p-value 0.12
summary(lm(Aged~Leave, df)) #p-value 0.58
summary(lm(Total~Leave, df)) #p-value 0.13
summary(lm(Aged~Scan, df)) #p-value 0.87
summary(lm(Total~Scan, df)) #p-value 0.54
df <- df[-1:-5,]#remove training weeks
summary(lm(Aged~Week, df)) #p-value 0.02
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Total~Week, df)) #p-value 0.12
summary(lm(Aged~Leave, df)) #p-value 0.58
summary(lm(Total~Leave, df)) #p-value 0.13
summary(lm(Aged~Scan, df)) #p-value 0.87
summary(lm(Total~Scan, df)) #p-value 0.54
df <- df[-1:-5,]#remove training weeks
summary(lm(Aged~Week, df)) #p-value 0.60
summary(lm(Aged~Leave, df)) #p-value 0.17
summary(lm(Total~Leave, df)) #p-value 0.16
summary(lm(Aged~Scan, df)) #p-value 0.22
summary(lm(Total~Scan, df)) #p-value 0.63
df <- df[-6,]#remove week out on leave entire week
summary(lm(Aged~Leave, df)) #p-value 0.63
summary(lm(Total~Leave, df)) #p-value 0.77
summary(lm(Aged~Scan, df)) #p-value 0.29
summary(lm(Total~Scan, df)) #p-value 0.80
df <- read_excel("Supervisory Docs/Personnel/Sandi Neidetcher/Sandi Weekly Productivity.xlsx")
summary(lm(Total~Week, df)) #p-value 0.12
# Load libraries
library(keras)
library(tensorflow)
# Check if TensorFlow backend is used
backend()
# Load the Iris dataset
data(iris)
head(iris)
# Preprocess the data
x <- as.matrix(iris[, 1:4])
y <- to_categorical(as.numeric(iris$Species) - 1)  # Convert species to one-hot encoding
data(iris)
X <- as.matrix(iris[, 1:4])  # Features
y <- as.integer(iris$Species) - 1  # Labels: Convert to numeric labels (0, 1, 2)
y <- to_categorical(y, num_classes = 3)
devtools::install_github("rstudio/tensorflow", force = TRUE)
devtools::install_github("rstudio/tensorflow", force = TRUE)
devtools::install_github("rstudio/keras", force = TRUE)
3
devtools::install_github("rstudio/kerasTuner", force = TRUE)
devtools::install_github("rstudio/kerasTuner", force = TRUE)
devtools::install_github('EagerAI/kerastuneR')
# Load libraries
library(keras)
library(tensorflow)
# Check if TensorFlow backend is used
backend()
# Load the Iris dataset
data(iris)
head(iris)
# Preprocess the data
x <- as.matrix(iris[, 1:4])
y <- to_categorical(as.numeric(iris$Species) - 1)  # Convert species to one-hot encoding
# Load necessary libraries
library(keras)
library(kerastuneR)
# Check TensorFlow version
tf$version$tensorflow
tensorflow::install_tensorflow()
kerastuneR::install_kerastuner()
keras::install_keras()
# Load necessary libraries
library(keras)
library(kerastunekerR)
library(kerastuneR)
library(tensorflow)
# Check TensorFlow version
tf$version$tensorflow
# Generate synthetic data for testing
set.seed(42)
x_train <- matrix(runif(400), ncol = 4)
y_train <- sample(0:1, 100, replace = TRUE)
# Initialize Hyperband tuner
tuner <- Hyperband(
build_model,
objective = 'val_accuracy',
max_epochs = 10,
directory = 'keras_tuner_dir',
project_name = 'simple_model'
)
reticulate::py_config()
reticulate::py_config()
kerastuneR::install_kerastuner()
reticulate::py_config()
# Load necessary libraries
library(keras)
library(kerastuneR)
library(tensorflow)
# Check TensorFlow version
tf$version$tensorflow
# Define a simple neural network building function
build_model <- function(hp) {
model <- keras_model_sequential()
# Tune number of units in the first dense layer
units <- hp$Int('units', min_value = 32, max_value = 128, step = 32)
model %>%
layer_dense(units = units, activation = 'relu', input_shape = c(4)) %>%
layer_dense(units = 1, activation = 'sigmoid')
# Compile the model
model %>% compile(
optimizer = 'adam',
loss = 'binary_crossentropy',
metrics = c('accuracy')
)
return(model)
}
# Generate synthetic data for testing
set.seed(42)
x_train <- matrix(runif(400), ncol = 4)
y_train <- sample(0:1, 100, replace = TRUE)
# Initialize Hyperband tuner
tuner <- Hyperband(
build_model,
objective = 'val_accuracy',
max_epochs = 10,
directory = 'keras_tuner_dir',
project_name = 'simple_model'
)
reticulate::py_config()
# Load necessary libraries
library(keras)
library(kerastuneR)
library(tensorflow)
# Load necessary libraries
library(keras)
library(kerastuneR)
reticulate::py_config()
# Check TensorFlow version
tf$version$tensorflow
tensorflow::install_tensorflow()
tensorflow::install_tensorflow()
tensorflow::install_tensorflow()
library(tidyverse)
library(readxl)
library(janitor)
library(scales)
library(FSA)
library(patchwork)
library(RODBC)
species <- 'ATKA MACKEREL' # Enter species
collection <- 'A20423B'  # Enter ageing collection
dbconnection <- odbcDriverConnect("Driver={SQL Server};Server={AKC0SS-VI-071.nmfs.local,1919};Database=AGE3;Trusted_Connection=yes;")
#age data
data <- sqlQuery(dbconnection,paste("SELECT A.collection_type, A.collection_year, A.cruise_number,
A.date_collected, A.final_age, A.final_method, A.readability,
A.length, A.read_age, A.region, A.sex, A.species_code,
A.specimen, A.test_age, A.ageing_collection, A.vessel_code,
A.weight, C.common_name
FROM process_all_ages_v AS A
JOIN species as C
ON A.species_code = C.species_code
WHERE  (C.common_name = '",species,"') AND
(A.ageing_collection = '",collection,"')", sep=""),believeNRows=FALSE)
odbcClose(dbconnection)
View(data)
#age data
data <- sqlQuery(dbconnection,paste("SELECT A.collection_type, A.collection_year, A.cruise_number,
A.date_collected, A.final_age, A.final_method, A.readability,
A.length, A.read_age, A.region, A.sex, A.species_code,
A.specimen, A.test_age, A.ageing_collection, A.vessel_code,
A.weight, C.common_name, A.timestamp
FROM process_all_ages_v AS A
JOIN species as C
ON A.species_code = C.species_code
WHERE  (C.common_name = '",species,"') AND
(A.ageing_collection = '",collection,"')", sep=""),believeNRows=FALSE)
dbconnection <- odbcDriverConnect("Driver={SQL Server};Server={AKC0SS-VI-071.nmfs.local,1919};Database=AGE3;Trusted_Connection=yes;")
#age data
data <- sqlQuery(dbconnection,paste("SELECT A.collection_type, A.collection_year, A.cruise_number,
A.date_collected, A.final_age, A.final_method, A.readability,
A.length, A.read_age, A.region, A.sex, A.species_code,
A.specimen, A.test_age, A.ageing_collection, A.vessel_code,
A.weight, C.common_name, A.timestamp
FROM process_all_ages_v AS A
JOIN species as C
ON A.species_code = C.species_code
WHERE  (C.common_name = '",species,"') AND
(A.ageing_collection = '",collection,"')", sep=""),believeNRows=FALSE)
View(data)
test<-subset(data,timestamp>0)
test<-subset(data,read_age>=0)
View(test)
wd <- "C:/Users/Derek.Chamberlin/Work/Research/TMA_FT_NIR_Uncertainty/nir_boot"
setwd(wd)
source(paste0(wd,"/R/Functions.R"))
nsim <- 2
#import TMA age error data, bias columns are (expected age-0.5)
{
TMA_bias <- matrix(ncol=7, nrow = 19)
TMA_bias[,1] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader1.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,2] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader2.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,3] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader3.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,4] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader4.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,5] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader5.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,6] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader6.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,7] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader7.csv", header=TRUE)[5,-1])-0.5)
colnames(TMA_bias) <- c("bias_R1", "bias_R2", "bias_R3", "bias_R4", "bias_R5", "bias_R6", "bias_R7")
}
{
TMA_sd <- matrix(ncol=7, nrow = 19)
TMA_sd[,1] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader1.csv", header=TRUE)[4,-1])
TMA_sd[,2] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader2.csv", header=TRUE)[4,-1])
TMA_sd[,3] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader3.csv", header=TRUE)[4,-1])
TMA_sd[,4] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader4.csv", header=TRUE)[4,-1])
TMA_sd[,5] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader5.csv", header=TRUE)[4,-1])
TMA_sd[,6] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader6.csv", header=TRUE)[4,-1])
TMA_sd[,7] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader7.csv", header=TRUE)[4,-1])
colnames(TMA_sd) <- c("SD_R1", "SD_R2", "SD_R3", "SD_R4", "SD_R5", "SD_R6", "SD_R7")
}
df <- read.csv(paste0("./data/AGP_MMCNN_BSsurvey_pollock2014to2018.csv"))
#This chunk won't be needed, need to expand age error mat so it goes out to age 23
train_dat <- subset(df, Age <= 18)
View(df)
#This chunk won't be needed, need to expand age error mat so it goes out to age 23
train_dat <- subset(df, final_age <= 18)
input_age <- df$final_age
input_age <- df$final_age
set.seed(581)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
min(input_age)
max(input_age)
plot(input_age)
input_age <- as.numeric(df$final_age)
max(input_age)
#This chunk won't be needed, need to expand age error mat so it goes out to age 23
train_dat <- subset(df, final_age <= 18)
train_dat <- subset(df, final_age >= 0)
input_age <- as.numeric(df$final_age)
min(input_age)
input_age
input_age <- as.numeric(df$final_age)
set.seed(581)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
train_dat <- subset(df, final_age > 0)
input_age <- as.numeric(df$final_age)
set.seed(581)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
View(TMA_bias)
View(TMA_sd)
View(TMA_sd)
View(TMA_bias)
wd <- "C:/Users/Derek.Chamberlin/Work/Research/TMA_FT_NIR_Uncertainty/nir_boot"
function (x, df1, df2, ncp, log = FALSE)
setwd(wd)
source(paste0(wd,"/R/Functions.R"))
nsim <- 2
#import TMA age error data, bias columns are (expected age-0.5)
{
TMA_bias <- matrix(ncol=7, nrow = 19)
TMA_bias[,1] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader1.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,2] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader2.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,3] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader3.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,4] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader4.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,5] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader5.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,6] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader6.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,7] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader7.csv", header=TRUE)[5,-1])-0.5)
colnames(TMA_bias) <- c("bias_R1", "bias_R2", "bias_R3", "bias_R4", "bias_R5", "bias_R6", "bias_R7")
}
{
TMA_sd <- matrix(ncol=7, nrow = 19)
TMA_sd[,1] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader1.csv", header=TRUE)[4,-1])
TMA_sd[,2] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader2.csv", header=TRUE)[4,-1])
TMA_sd[,3] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader3.csv", header=TRUE)[4,-1])
TMA_sd[,4] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader4.csv", header=TRUE)[4,-1])
TMA_sd[,5] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader5.csv", header=TRUE)[4,-1])
TMA_sd[,6] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader6.csv", header=TRUE)[4,-1])
TMA_sd[,7] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader7.csv", header=TRUE)[4,-1])
colnames(TMA_sd) <- c("SD_R1", "SD_R2", "SD_R3", "SD_R4", "SD_R5", "SD_R6", "SD_R7")
}
df <- read.csv(paste0("./data/AGP_MMCNN_BSsurvey_pollock2014to2018.csv"))
#This chunk won't be needed, need to expand age error mat so it goes out to age 23
train_dat <- subset(df, final_age <= 18)
train_dat <- subset(df, final_age > 0)
input_age <- as.numeric(df$final_age)
set.seed(581)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
debug(boot_age)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
undebug(boot_age)
undebug(boot_age)
debug(samp_age)
View(TMA_bias)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
input_age
getOption("max.print")
df <- read.csv(paste0("./data/AGP_MMCNN_BSsurvey_pollock2014to2018.csv"))
wd <- "C:/Users/Derek.Chamberlin/Work/Research/TMA_FT_NIR_Uncertainty/nir_boot"
setwd(wd)
source(paste0(wd,"/R/Functions.R"))
nsim <- 2
#import TMA age error data, bias columns are (expected age-0.5)
{
TMA_bias <- matrix(ncol=7, nrow = 19)
TMA_bias[,1] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader1.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,2] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader2.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,3] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader3.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,4] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader4.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,5] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader5.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,6] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader6.csv", header=TRUE)[5,-1])-0.5)
TMA_bias[,7] <- (as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader7.csv", header=TRUE)[5,-1])-0.5)
colnames(TMA_bias) <- c("bias_R1", "bias_R2", "bias_R3", "bias_R4", "bias_R5", "bias_R6", "bias_R7")
}
{
TMA_sd <- matrix(ncol=7, nrow = 19)
TMA_sd[,1] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader1.csv", header=TRUE)[4,-1])
TMA_sd[,2] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader2.csv", header=TRUE)[4,-1])
TMA_sd[,3] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader3.csv", header=TRUE)[4,-1])
TMA_sd[,4] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader4.csv", header=TRUE)[4,-1])
TMA_sd[,5] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader5.csv", header=TRUE)[4,-1])
TMA_sd[,6] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader6.csv", header=TRUE)[4,-1])
TMA_sd[,7] <- as.numeric(read.csv("./data/7_reader_TMA_TMB/Results/Pollock SS3_format_Reader7.csv", header=TRUE)[4,-1])
colnames(TMA_sd) <- c("SD_R1", "SD_R2", "SD_R3", "SD_R4", "SD_R5", "SD_R6", "SD_R7")
}
df <- read.csv(paste0("./data/AGP_MMCNN_BSsurvey_pollock2014to2018.csv"))
#This chunk won't be needed, need to expand age error mat so it goes out to age 23
df <- subset(df, final_age <= 18)
input_age <- as.numeric(df$final_age)
set.seed(581)
new_ages <- boot_age(nsim, input_age, TMA_bias, TMA_sd) #bootstrap age estimates
View(new_ages)
dir.create("./sims", showWarnings = FALSE) #creat a folder to store all the sims
#replace original age estimates with bootstrap ages
for (i in 1:ncol(new_ages)) {
dir.create(paste0("./sims/",i),showWarnings = FALSE)
#file.copy(from = paste0("./python/",file_list), to = paste0("./sims/",i),  overwrite = TRUE, recursive = TRUE,
#          copy.mode = TRUE)
df$final_age <- new_ages[,i]
write.csv(df, paste0("./sims/",i,"/input.csv"), row.names=FALSE)
}
